<project><prname>Introduction to machine learning</prname>
<idnum>4468</idnum>
<terminologyset>cegep</terminologyset>
<workflow><wfname>Introduction to machine learning</wfname>
<wfauthor>Instructor</wfauthor>
<wfdescription>&lt;p&gt;This course is the introduction todata analysis and machine learning (ML) algorithms/models/methodologies. Based on the applications in machine learning /AI in multiple businesses (i.e. finance, user behavior analysis, retailer services, etc.), the detailed models using ML to solve these practical questions will be presented and the implementation of the code will be guided step by step. &lt;/p&gt;&lt;p&gt;The following topics related to general machine learning techniques will be covered: common-used data analysis/machine learning programming tools, exploratory data analysis, feature engineering, supervised/unsupervised learning, regression, classification, tree-based models, boosting and ensemble methods, time series, data visualization, clustering, dimensionality reduction and their applications in various business cases.&lt;/p&gt;</wfdescription>
<wfid>1</wfid>
<wftype>course</wftype>
<usedwfARRAY></usedwfARRAY>
<tagsetARRAY>541,559,2454</tagsetARRAY>
<wfdata><column><columnname>HW</columnname>
<columntext>Preparation (students)</columntext>
<columnnodetext>Preparation (students)</columnnodetext>
<columnoutcomevisibility>undefined</columnoutcomevisibility>
</column>
<column><columnname>AC</columnname>
<columntext>Lesson / Lecture</columntext>
<columnnodetext>Lesson / Lecture</columnnodetext>
<columnoutcomevisibility>true</columnoutcomevisibility>
</column>
<column><columnname>CUS3</columnname>
<columnimage>gears</columnimage>
<columncolour>#6738ff</columncolour>
<columntext>In Class Practice</columntext>
<columnnodetext>In Class Practice</columnnodetext>
<columnoutcomevisibility>undefined</columnoutcomevisibility>
</column>
<column><columnname>CUS2</columnname>
<columnimage>general</columnimage>
<columncolour>#a3b9df</columncolour>
<columntext>Offline Assignments</columntext>
<columnnodetext>Offline Assignments</columnnodetext>
<columnoutcomevisibility>undefined</columnoutcomevisibility>
</column>
<column><columnname>CUS1</columnname>
<columnimage>solo</columnimage>
<columncolour>#a3b9df</columncolour>
<columntext>Tutorial (ITS)</columntext>
<columnnodetext>Tutorial (ITS)</columnnodetext>
<columnoutcomevisibility>undefined</columnoutcomevisibility>
</column>
<column><columnname>SA</columnname>
</column>
<week><weekid>278</weekid>
<weekname>Week 1: general terms and development review for ML</weekname>
<node><name>pre-requisite knowledge in ML and AI</name>
<id>3950</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>HW</column>
<textHTML>&lt;ul&gt;&lt;li&gt;important concepts and terminologies in ML/AI&lt;/li&gt;&lt;li&gt;Data mining, machine learning and AI definition and their relationship/differences&lt;/li&gt;&lt;li&gt;often-used platform and toolbox in ML/AI&lt;/li&gt;&lt;li&gt;Role /work flow as data analyst/scientist/engineer&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>163.59373474121094</textheight>
<isdropped>true</isdropped>
<link><targetid>3951</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>561</nodetagid>
</nodetag>
<nodetag><nodetagid>560</nodetagid>
</nodetag>
</node>
<node><name>No offline assignment for session #1</name>
<id>3952</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS2</column>
<textHTML>undefined</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>9.993749618530273</textheight>
<isdropped>true</isdropped>
</node>
<node><name>1: Linear Algebra Basics: good to ask students review after session #1</name>
<id>279</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;p&gt;Why Learn Linear Algebra?&lt;/p&gt;&lt;p&gt;Vectors and Matrices and Scalars&lt;/p&gt;&lt;p&gt;Addition and Scalar Multiplication and Transpose&lt;/p&gt;&lt;p&gt;Dot Product&lt;/p&gt;&lt;p&gt;Norm and Euclidean Distance&lt;/p&gt;&lt;p&gt;Matrix Multiplication&lt;/p&gt;&lt;p&gt;Identity Matrix&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>155.17498779296875</textheight>
<isdropped>true</isdropped>
<link><targetid>280</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
</node>
<node><name>2: Probability Basics	</name>
<id>280</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;p&gt;Introduction to Probability&lt;/p&gt;&lt;p&gt;Discrete vs. Continuous Random Variables&lt;/p&gt;&lt;p&gt;Expected Value vs. Sample Mean&lt;/p&gt;&lt;p&gt;Variance and Standard Deviation&lt;/p&gt;&lt;p&gt;Binomial Distribution&lt;/p&gt;&lt;p&gt;Normal distribution&lt;/p&gt;&lt;p&gt;conditional probability&lt;/p&gt;&lt;p&gt;Joint and marginal probability&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>160.17185974121094</textheight>
<isdropped>true</isdropped>
<nodetag><nodetagid>2455</nodetagid>
</nodetag>
</node>
<node><name>Session #1:  general introduction development tools</name>
<id>3951</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>AC</column>
<textHTML>&lt;ul&gt;&lt;li&gt;What is machine learning (ML) and artificial intelligence (AI)&lt;/li&gt;&lt;li&gt;What are their relationships and differences&lt;/li&gt;&lt;li&gt;Over view of often-used toolkits and programming languages in ML/AI development&lt;/li&gt;&lt;li&gt;Career path and learning path of being a data scientist and data engineer&lt;/li&gt;&lt;li&gt;Overview of applications in diverse businesses for ML/AI&lt;/li&gt;&lt;li&gt;Overview and guideline for ML libs installation and environment setting&lt;/li&gt;&lt;li&gt;Assign multiple projects for students according to their timeline and difficulties of the project&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>264.39373779296875</textheight>
<timevalue>180</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>12</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>543</nodetagid>
</nodetag>
<nodetag><nodetagid>557</nodetagid>
</nodetag>
<nodetag><nodetagid>560</nodetagid>
</nodetag>
<nodetag><nodetagid>561</nodetagid>
</nodetag>
<nodetag><nodetagid>2493</nodetagid>
</nodetag>
</node>
</week>
<week><weekid>2</weekid>
<weekname>Week 2: general methodologies in ML</weekname>
<node><name>Korbit #2: ML overview path</name>
<id>4207</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;p&gt;To master session #2, Korbit can help with&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Motivation of ML&lt;/li&gt;&lt;li&gt;Supervised learning&lt;/li&gt;&lt;li&gt;Overfitting and underfitting&lt;/li&gt;&lt;li&gt;Overview of cross validation (HD)&lt;/li&gt;&lt;li&gt;Bias-variance trade-off and decomposition&lt;/li&gt;&lt;li&gt;Gradient descent&lt;/li&gt;&lt;li&gt;Summary of ML&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>163.59373474121094</textheight>
<isdropped>true</isdropped>
<link><targetid>12</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>2460</nodetagid>
</nodetag>
<nodetag><nodetagid>2483</nodetagid>
</nodetag>
<nodetag><nodetagid>2484</nodetagid>
</nodetag>
<nodetag><nodetagid>2487</nodetagid>
</nodetag>
<nodetag><nodetagid>2488</nodetagid>
</nodetag>
<nodetag><nodetagid>2489</nodetagid>
</nodetag>
<nodetag><nodetagid>2491</nodetagid>
</nodetag>
<nodetag><nodetagid>2493</nodetagid>
</nodetag>
</node>
<node><name>Some readings on ML methodologies</name>
<id>3953</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>HW</column>
<textHTML>&lt;ul&gt;&lt;li&gt;Types of learning (supervised &amp;amp; unsupervised)&lt;/li&gt;&lt;li&gt;overfitting and underfitting&lt;/li&gt;&lt;li&gt;Generalization and robustness in ML&lt;/li&gt;&lt;li&gt;Overfit and underfit concept&lt;/li&gt;&lt;li&gt;Identify data format(input features and target)&lt;/li&gt;&lt;li&gt;How to prepare data (split dataset)&lt;/li&gt;&lt;li&gt;Train, validation and test and how they work&lt;/li&gt;&lt;li&gt;Concept of loss function&lt;/li&gt;&lt;li&gt;Cross validation strategy&lt;/li&gt;&lt;li&gt;What are evaluation metrics used in ML&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>235.59373474121094</textheight>
<isdropped>true</isdropped>
<link><targetid>12</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
</node>
<node><name>General methogologies</name>
<id>12</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>AC</column>
<textHTML>&lt;p&gt;Provide a comprehensive bigger picture and methodologies used in ML and key techniques&lt;/p&gt;&lt;ul&gt;&lt;li&gt;generalization of ML&lt;/li&gt;&lt;li&gt;overfitting and underfitting&lt;/li&gt;&lt;li&gt;learning types and format&lt;/li&gt;&lt;li&gt;split data into train, valid and test&lt;/li&gt;&lt;li&gt;Categorical and numerical features&lt;/li&gt;&lt;li&gt;loss function as objective&lt;/li&gt;&lt;li&gt;why does ML use loss&lt;/li&gt;&lt;li&gt;loss functions for classification and regression (just overview and concept build)&lt;/li&gt;&lt;li&gt;how to learn(gradient descent)&lt;/li&gt;&lt;li&gt;visualize how gradient decent works&lt;/li&gt;&lt;li&gt;Cross validation strategy&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>249.9937286376953</textheight>
<timevalue>110</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>10</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<link><targetid>3956</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<link><targetid>3955</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>544</nodetagid>
</nodetag>
<nodetag><nodetagid>549</nodetagid>
</nodetag>
<nodetag><nodetagid>550</nodetagid>
</nodetag>
<nodetag><nodetagid>553</nodetagid>
</nodetag>
<nodetag><nodetagid>555</nodetagid>
</nodetag>
<nodetag><nodetagid>548</nodetagid>
</nodetag>
<nodetag><nodetagid>563</nodetagid>
</nodetag>
<nodetag><nodetagid>2460</nodetagid>
</nodetag>
<nodetag><nodetagid>2461</nodetagid>
</nodetag>
<nodetag><nodetagid>2462</nodetagid>
</nodetag>
<nodetag><nodetagid>2474</nodetagid>
</nodetag>
<nodetag><nodetagid>2475</nodetagid>
</nodetag>
<nodetag><nodetagid>2476</nodetagid>
</nodetag>
<nodetag><nodetagid>2483</nodetagid>
</nodetag>
<nodetag><nodetagid>2484</nodetagid>
</nodetag>
<nodetag><nodetagid>2487</nodetagid>
</nodetag>
<nodetag><nodetagid>2488</nodetagid>
</nodetag>
<nodetag><nodetagid>2491</nodetagid>
</nodetag>
</node>
<node><name>#2 session in-class code demo and practice</name>
<id>3955</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS3</column>
<textHTML>&lt;ul&gt;&lt;li&gt;Read/load data, split data by input features and target variables using pandas&lt;/li&gt;&lt;li&gt;Identify categorical and numerical features in the dataset&lt;/li&gt;&lt;li&gt;Split data into train, validation and test by sklearn API&lt;/li&gt;&lt;li&gt;Split total data by cross validation strategy using sklearn API&lt;/li&gt;&lt;li&gt;Get to know loss functions provided by sklearn API&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>192.39373779296875</textheight>
<timevalue>70</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<nodetag><nodetagid>545</nodetagid>
</nodetag>
<nodetag><nodetagid>547</nodetagid>
</nodetag>
<nodetag><nodetagid>560</nodetagid>
</nodetag>
<nodetag><nodetagid>561</nodetagid>
</nodetag>
<nodetag><nodetagid>562</nodetagid>
</nodetag>
<nodetag><nodetagid>563</nodetagid>
</nodetag>
<nodetag><nodetagid>2460</nodetagid>
</nodetag>
<nodetag><nodetagid>2461</nodetagid>
</nodetag>
<nodetag><nodetagid>2462</nodetagid>
</nodetag>
</node>
<node><name>#2 Theoretical assignment </name>
<id>3956</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS2</column>
<textHTML>&lt;p&gt;Provided theoretical assignment in order to&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Understand supervised/unsupervised learning tasks and classification/regression&lt;/li&gt;&lt;li&gt;data splitting strategies&lt;/li&gt;&lt;li&gt;imbalanced dataset (extensive reading and review)&lt;/li&gt;&lt;li&gt;learning rule calculation for linear regression(bonus point)&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>163.59373474121094</textheight>
<isdropped>true</isdropped>
<link><targetid>3957</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>542</nodetagid>
</nodetag>
<nodetag><nodetagid>545</nodetagid>
</nodetag>
<nodetag><nodetagid>547</nodetagid>
</nodetag>
<nodetag><nodetagid>560</nodetagid>
</nodetag>
<nodetag><nodetagid>561</nodetagid>
</nodetag>
<nodetag><nodetagid>563</nodetagid>
</nodetag>
<nodetag><nodetagid>564</nodetagid>
</nodetag>
<nodetag><nodetagid>2458</nodetagid>
</nodetag>
</node>
<node><name>#2 Coding assignment</name>
<id>3957</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS2</column>
<textHTML>&lt;p&gt;for students's projects:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;practice data splitting and sklearn API&lt;/li&gt;&lt;li&gt;practice cross validation splitting and sklearn API&lt;/li&gt;&lt;li&gt;practice calculate loss using sklearn API&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>105.99374389648438</textheight>
<isdropped>true</isdropped>
<nodetag><nodetagid>559</nodetagid>
</nodetag>
<nodetag><nodetagid>2460</nodetagid>
</nodetag>
<nodetag><nodetagid>2461</nodetagid>
</nodetag>
<nodetag><nodetagid>2462</nodetagid>
</nodetag>
</node>
</week>
<week><weekid>4</weekid>
<weekname>Week 3: Data preprocessing : data IO operation</weekname>
<node><name>Some pre-readings</name>
<id>146</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>HW</column>
<textHTML>&lt;p&gt;Provide some reading lists for understanding:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Categorical and numerical variables&lt;/li&gt;&lt;li&gt;refresh of pandas data processing API&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>77.1937484741211</textheight>
<isdropped>true</isdropped>
<link><targetid>10</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
</node>
<node><name>Data preprocessing (I)--- basic processing</name>
<id>10</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>AC</column>
<textHTML>&lt;p&gt;Lecture includes the following concepts &amp;amp; topics:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Missing data analysis&lt;/li&gt;&lt;li&gt;Data type check and conversion&lt;/li&gt;&lt;li&gt;Indexing and query data by conditions&lt;/li&gt;&lt;li&gt;Groupby and merge tables&lt;/li&gt;&lt;li&gt;Lambda expressions in pandas&lt;/li&gt;&lt;li&gt;Process categorical data (label encoding and one hot encoding)&lt;/li&gt;&lt;li&gt;Process numerical data(normalize)&lt;/li&gt;&lt;li&gt;Sparse matrix for large dimensional features&lt;/li&gt;&lt;li&gt;Memory management skills for larger data&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>235.59373474121094</textheight>
<timevalue>100</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>4078</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<link><targetid>23</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>560</nodetagid>
</nodetag>
<nodetag><nodetagid>561</nodetagid>
</nodetag>
<nodetag><nodetagid>544</nodetagid>
</nodetag>
<nodetag><nodetagid>2460</nodetagid>
</nodetag>
<nodetag><nodetagid>2461</nodetagid>
</nodetag>
<nodetag><nodetagid>2462</nodetagid>
</nodetag>
<nodetag><nodetagid>2463</nodetagid>
</nodetag>
<nodetag><nodetagid>2466</nodetagid>
</nodetag>
<nodetag><nodetagid>553</nodetagid>
</nodetag>
<nodetag><nodetagid>548</nodetagid>
</nodetag>
<nodetag><nodetagid>555</nodetagid>
</nodetag>
<nodetag><nodetagid>550</nodetagid>
</nodetag>
</node>
<node><name>Data preprocessing - code practice in-class</name>
<id>4078</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS3</column>
<textHTML>&lt;p&gt;we provided coding practice for preprocessing in pandas using student's project datasets as demo&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Data I/O in pandas &lt;/li&gt;&lt;li&gt;Data type conversion&lt;/li&gt;&lt;li&gt;Find and fill missing data&lt;/li&gt;&lt;li&gt;Indexing subset from total data &lt;/li&gt;&lt;li&gt;Table aggregation, join and merge&lt;/li&gt;&lt;li&gt;Fast processing using lambda expression&lt;/li&gt;&lt;li&gt;Label &amp;amp; one-hot encoding categorical data&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>221.19374084472656</textheight>
<timevalue>90</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>4079</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>545</nodetagid>
</nodetag>
<nodetag><nodetagid>547</nodetagid>
</nodetag>
<nodetag><nodetagid>2461</nodetagid>
</nodetag>
<nodetag><nodetagid>2463</nodetagid>
</nodetag>
</node>
<node><name>3: Data Preprocessing (Week 3)</name>
<id>2425</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;p&gt;What is a Dataset?&lt;/p&gt;&lt;p&gt;Exploratory Data Analysis&lt;/p&gt;&lt;p&gt;Overview of Data Preprocessing&lt;/p&gt;&lt;p&gt;One-Hot Encoding&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>101.98124694824219</textheight>
<isdropped>true</isdropped>
<nodetag><nodetagid>2460</nodetagid>
</nodetag>
<nodetag><nodetagid>2461</nodetagid>
</nodetag>
<nodetag><nodetagid>2462</nodetagid>
</nodetag>
</node>
<node><name>#3 Assignment for basic processing</name>
<id>4079</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS2</column>
<textHTML>&lt;p&gt;Asked students to practice all aspects of basic data preprocessing based on their own project datasets&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>53.193748474121094</textheight>
<isdropped>true</isdropped>
</node>
</week>
<week><weekid>5</weekid>
<weekname>Week 4: data processing: feature engineering</weekname>
<node><name>4: Data Preprocessing II (Week 4)</name>
<id>2437</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;p&gt;Feature Engineering&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;feature selection&lt;/p&gt;&lt;p&gt;feature scaling&lt;/p&gt;&lt;p&gt;feature importance&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>121.37812042236328</textheight>
<isdropped>true</isdropped>
<nodetag><nodetagid>2464</nodetagid>
</nodetag>
<nodetag><nodetagid>2465</nodetagid>
</nodetag>
<nodetag><nodetagid>2466</nodetagid>
</nodetag>
<nodetag><nodetagid>2467</nodetagid>
</nodetag>
</node>
<node><name>Data Preprocessing 2: feature engineering</name>
<id>23</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>AC</column>
<textHTML>&lt;p&gt;Lecture on feature engineering, including the following concepts and processes:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Feature engineering for timestamp/date related features&lt;/li&gt;&lt;li&gt;Feature engineering for categorical features&lt;/li&gt;&lt;li&gt;Feature engineering at aggregation level stats&lt;/li&gt;&lt;li&gt;Feature engineering on business sense&lt;/li&gt;&lt;li&gt;Feature selection skills&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>177.99374389648438</textheight>
<timevalue>100</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>139</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>563</nodetagid>
</nodetag>
<nodetag><nodetagid>2467</nodetagid>
</nodetag>
<nodetag><nodetagid>555</nodetagid>
</nodetag>
<nodetag><nodetagid>544</nodetagid>
</nodetag>
<nodetag><nodetagid>550</nodetagid>
</nodetag>
</node>
<node><name>Feature engineering code - in-class demo</name>
<id>139</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS3</column>
<textHTML>&lt;p&gt;In-class code practice on feature engineering includes:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Process timestamp, extract time information&lt;/li&gt;&lt;li&gt;Extract features on categorical data&lt;/li&gt;&lt;li&gt;feature aggregation&lt;/li&gt;&lt;li&gt;Customize features based on business understanding (open practice)&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>149.19374084472656</textheight>
<timevalue>80</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>101</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<link><targetid>148</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>544</nodetagid>
</nodetag>
<nodetag><nodetagid>550</nodetagid>
</nodetag>
<nodetag><nodetagid>545</nodetagid>
</nodetag>
<nodetag><nodetagid>547</nodetagid>
</nodetag>
<nodetag><nodetagid>561</nodetagid>
</nodetag>
<nodetag><nodetagid>563</nodetagid>
</nodetag>
<nodetag><nodetagid>564</nodetagid>
</nodetag>
<nodetag><nodetagid>2464</nodetagid>
</nodetag>
<nodetag><nodetagid>2465</nodetagid>
</nodetag>
<nodetag><nodetagid>2466</nodetagid>
</nodetag>
<nodetag><nodetagid>2467</nodetagid>
</nodetag>
</node>
<node><name>#4 Assignment _feature engineering</name>
<id>148</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS2</column>
<textHTML>&lt;p&gt;&lt;strong&gt;Assignment for feature engineering&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Replay in-class code demo by using your own dataset&lt;/li&gt;&lt;li&gt;Come up with new business-orientated features based on your own project dataset&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>120.39374542236328</textheight>
<isdropped>true</isdropped>
</node>
</week>
<week><weekid>6</weekid>
<weekname>Week 5: Supervised learning (I): classification models</weekname>
<node><name>5 classification models</name>
<id>4208</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;p&gt;Korbit can help with&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Logistic regression basic&lt;/li&gt;&lt;li&gt;Sigmoid function&lt;/li&gt;&lt;li&gt;Binary classification and imbalanced classes&lt;/li&gt;&lt;li&gt;binary classification&lt;/li&gt;&lt;li&gt;Evaluation metrics for classification&lt;/li&gt;&lt;li&gt;Parameters and hyper-parameters&lt;/li&gt;&lt;li&gt;Hyperparameter tuning&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>163.59373474121094</textheight>
<isdropped>true</isdropped>
<link><targetid>101</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>2472</nodetagid>
</nodetag>
<nodetag><nodetagid>2473</nodetagid>
</nodetag>
<nodetag><nodetagid>2474</nodetagid>
</nodetag>
<nodetag><nodetagid>2475</nodetagid>
</nodetag>
<nodetag><nodetagid>2476</nodetagid>
</nodetag>
<nodetag><nodetagid>2480</nodetagid>
</nodetag>
<nodetag><nodetagid>2481</nodetagid>
</nodetag>
</node>
<node><name>Pre-readings</name>
<id>4080</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>HW</column>
<textHTML>&lt;ul&gt;&lt;li&gt;Tree based models&lt;/li&gt;&lt;li&gt;Entropy and information gain&lt;/li&gt;&lt;li&gt;Precision and recall, F1 score&lt;/li&gt;&lt;li&gt;ROC-AUC score&lt;/li&gt;&lt;li&gt;Random Forest &lt;/li&gt;&lt;li&gt;Gradient boosting tree classifier&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>120.39374542236328</textheight>
<isdropped>true</isdropped>
<link><targetid>101</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
</node>
<node><name>Classification models</name>
<id>101</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>AC</column>
<textHTML>&lt;p&gt;Lecture on classification models, including the following concepts and processes:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Linear classifier ; perceptron and logistic regression&lt;/li&gt;&lt;li&gt;Log loss for binary classification&lt;/li&gt;&lt;li&gt;Softmax for multi-class classification &lt;/li&gt;&lt;li&gt;Sigmoid activation function for output&lt;/li&gt;&lt;li&gt;Decision tree and its principals&lt;/li&gt;&lt;li&gt;Entropy and information gain&lt;/li&gt;&lt;li&gt;Shannon information and its general property&lt;/li&gt;&lt;li&gt;Random forest &lt;/li&gt;&lt;li&gt;Gradient boosting machine&lt;/li&gt;&lt;li&gt;Evaluation metrics for classification&lt;/li&gt;&lt;li class="ql-indent-1"&gt;F1 score, confusion matrix&lt;/li&gt;&lt;li class="ql-indent-1"&gt;ROC curve&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>264.39373779296875</textheight>
<timevalue>130</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>140</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>563</nodetagid>
</nodetag>
<nodetag><nodetagid>544</nodetagid>
</nodetag>
<nodetag><nodetagid>549</nodetagid>
</nodetag>
<nodetag><nodetagid>550</nodetagid>
</nodetag>
<nodetag><nodetagid>551</nodetagid>
</nodetag>
<nodetag><nodetagid>554</nodetagid>
</nodetag>
<nodetag><nodetagid>560</nodetagid>
</nodetag>
<nodetag><nodetagid>562</nodetagid>
</nodetag>
<nodetag><nodetagid>564</nodetagid>
</nodetag>
<nodetag><nodetagid>2472</nodetagid>
</nodetag>
<nodetag><nodetagid>2473</nodetagid>
</nodetag>
<nodetag><nodetagid>2474</nodetagid>
</nodetag>
<nodetag><nodetagid>2475</nodetagid>
</nodetag>
<nodetag><nodetagid>2476</nodetagid>
</nodetag>
<nodetag><nodetagid>2490</nodetagid>
</nodetag>
</node>
<node><name>5: Train first model by classifier</name>
<id>140</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS3</column>
<textHTML>&lt;p&gt;Build first model pipeline using linear classifier (perceptron) and nonlinear classifier (random forest and gradient boosting machine)&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>53.193748474121094</textheight>
<timevalue>50</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>150</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<link><targetid>121</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>555</nodetagid>
</nodetag>
</node>
<node><name>#5 assignment : theory</name>
<id>150</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS2</column>
<textHTML>&lt;p&gt;&lt;strong&gt;#5 theory assignment includes&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;understand entropy and its property&lt;/li&gt;&lt;li&gt;derive learning rule for logistic regression based on binary log-loss&lt;/li&gt;&lt;li&gt;understanding F1 score&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>105.99374389648438</textheight>
<isdropped>true</isdropped>
</node>
<node><name>#5 code assignment</name>
<id>4081</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS2</column>
<textHTML>&lt;p&gt;Train your base-line model by random forest and perceptron&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>38.79374694824219</textheight>
<isdropped>true</isdropped>
</node>
</week>
<week><weekid>21</weekid>
<weekname>Week 6: supervised learning (II): regression, regularization and ensemble methods</weekname>
<node><name>Pre-readings</name>
<id>4337</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>HW</column>
<textHTML>&lt;ul&gt;&lt;li&gt;Regularization and  penalty in ML&lt;/li&gt;&lt;li&gt;L1 and L2 mathematical principals&lt;/li&gt;&lt;li&gt;Ensemble methods&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>77.1937484741211</textheight>
<isdropped>true</isdropped>
<link><targetid>121</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
</node>
<node><name>6 Regression and regularization</name>
<id>4209</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;ul&gt;&lt;li&gt;Linear regression&lt;/li&gt;&lt;li&gt;Hyperparameters tuning&lt;/li&gt;&lt;li&gt;Regularization&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>77.1937484741211</textheight>
<isdropped>true</isdropped>
<link><targetid>141</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>2477</nodetagid>
</nodetag>
<nodetag><nodetagid>2478</nodetagid>
</nodetag>
<nodetag><nodetagid>2480</nodetagid>
</nodetag>
<nodetag><nodetagid>2481</nodetagid>
</nodetag>
</node>
<node><name>Regression and regularization</name>
<id>121</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>AC</column>
<textHTML>&lt;p&gt;Lecture on Regression, including the following concepts:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Linear regression&lt;/li&gt;&lt;li&gt;Regularization (L1 and L2)&lt;/li&gt;&lt;li&gt;Ensemble: bagging and boosting&lt;/li&gt;&lt;li&gt;LightGBM and Xgboost introduction&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>120.39374542236328</textheight>
<timevalue>100</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>141</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>562</nodetagid>
</nodetag>
<nodetag><nodetagid>2472</nodetagid>
</nodetag>
<nodetag><nodetagid>2473</nodetagid>
</nodetag>
<nodetag><nodetagid>2474</nodetagid>
</nodetag>
<nodetag><nodetagid>2475</nodetagid>
</nodetag>
<nodetag><nodetagid>2476</nodetagid>
</nodetag>
<nodetag><nodetagid>2477</nodetagid>
</nodetag>
<nodetag><nodetagid>2478</nodetagid>
</nodetag>
<nodetag><nodetagid>2481</nodetagid>
</nodetag>
<nodetag><nodetagid>2480</nodetagid>
</nodetag>
<nodetag><nodetagid>2485</nodetagid>
</nodetag>
<nodetag><nodetagid>2486</nodetagid>
</nodetag>
<nodetag><nodetagid>2490</nodetagid>
</nodetag>
<nodetag><nodetagid>2491</nodetagid>
</nodetag>
</node>
<node><name>#6  in-class coding demo</name>
<id>141</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS3</column>
<textHTML>&lt;ul&gt;&lt;li&gt;Train lightGBM&lt;/li&gt;&lt;li&gt;Hyper-parameters tuning in lightGBM&lt;/li&gt;&lt;li&gt;Learning rate, early-stopping tuning&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>77.1937484741211</textheight>
<timevalue>80</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>124</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<link><targetid>153</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>554</nodetagid>
</nodetag>
</node>
<node><name>#6 assignment</name>
<id>153</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS2</column>
<textHTML>&lt;p&gt;&lt;strong&gt;Project coding practice/ activity&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;train models using lightGBM and hyperparameter tuning, early stopping&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>77.58749389648438</textheight>
<isdropped>true</isdropped>
</node>
</week>
<week><weekid>115</weekid>
<weekname>Week 7: advanced feature engineering, Bayesian model, docker image
</weekname>
<node><name>Prepare to install docker image toolbox</name>
<id>4338</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>HW</column>
<textHTML>&lt;ul&gt;&lt;li&gt;review and install docker image box&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>62.79374694824219</textheight>
<isdropped>true</isdropped>
<link><targetid>124</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
</node>
<node><name>Advanced feature engineering, docker image</name>
<id>124</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>AC</column>
<textHTML>&lt;p&gt;Lecture on advanced feature engineering includes&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Feature importance and rank&lt;/li&gt;&lt;li&gt;Feature selection skills&lt;/li&gt;&lt;li&gt;Target encoding skill&lt;/li&gt;&lt;li&gt;Bayesian models in probability perspective&lt;/li&gt;&lt;li&gt;Spam mail detection overview by naive Bayes&lt;/li&gt;&lt;li&gt;Docker image: shift your code entirely to clients&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>192.39373779296875</textheight>
<timevalue>90</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>142</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<link><targetid>127</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>562</nodetagid>
</nodetag>
<nodetag><nodetagid>2492</nodetagid>
</nodetag>
<nodetag><nodetagid>2464</nodetagid>
</nodetag>
<nodetag><nodetagid>2465</nodetagid>
</nodetag>
<nodetag><nodetagid>556</nodetagid>
</nodetag>
<nodetag><nodetagid>543</nodetagid>
</nodetag>
<nodetag><nodetagid>544</nodetagid>
</nodetag>
<nodetag><nodetagid>550</nodetagid>
</nodetag>
<nodetag><nodetagid>548</nodetagid>
</nodetag>
<nodetag><nodetagid>561</nodetagid>
</nodetag>
<nodetag><nodetagid>564</nodetagid>
</nodetag>
</node>
<node><name>#7 in-class practice</name>
<id>142</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS3</column>
<textHTML>&lt;ul&gt;&lt;li&gt;Target encoding&lt;/li&gt;&lt;li&gt;Other advanced feature engineering skills&lt;/li&gt;&lt;li&gt;create docker images step by step&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>91.59374237060547</textheight>
<timevalue>90</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>156</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>556</nodetagid>
</nodetag>
</node>
<node><name>#7 did not have mapped content</name>
<id>4340</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>undefined</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>100</textheight>
</node>
<node><name>#7 assignment</name>
<id>156</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS2</column>
<textHTML>&lt;ul&gt;&lt;li&gt;Apply target encoding on project data&lt;/li&gt;&lt;li&gt;Fine tune pipeline model&lt;/li&gt;&lt;li&gt;Use feature selection and rank to improve model performance&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>91.59374237060547</textheight>
<isdropped>true</isdropped>
</node>
</week>
<week><weekid>119</weekid>
<weekname>Week 8: time series analysis
</weekname>
<node><name>Time series analysis</name>
<id>127</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>AC</column>
<textHTML>&lt;p&gt;Lecture on time series analysis, including the following &lt;/p&gt;&lt;ul&gt;&lt;li&gt;Basic property of time series data&lt;/li&gt;&lt;li&gt;Some important index in time series data&lt;/li&gt;&lt;li&gt;Strategy to split time series data&lt;/li&gt;&lt;li&gt;Moving averge&lt;/li&gt;&lt;li&gt;Culmulative sum&lt;/li&gt;&lt;li&gt;Lagged features&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>163.59373474121094</textheight>
<timevalue>120</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>143</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>564</nodetagid>
</nodetag>
<nodetag><nodetagid>551</nodetagid>
</nodetag>
<nodetag><nodetagid>2481</nodetagid>
</nodetag>
<nodetag><nodetagid>2467</nodetagid>
</nodetag>
<nodetag><nodetagid>2466</nodetagid>
</nodetag>
<nodetag><nodetagid>2465</nodetagid>
</nodetag>
<nodetag><nodetagid>2464</nodetagid>
</nodetag>
<nodetag><nodetagid>563</nodetagid>
</nodetag>
<nodetag><nodetagid>561</nodetagid>
</nodetag>
<nodetag><nodetagid>548</nodetagid>
</nodetag>
<nodetag><nodetagid>556</nodetagid>
</nodetag>
<nodetag><nodetagid>555</nodetagid>
</nodetag>
<nodetag><nodetagid>549</nodetagid>
</nodetag>
<nodetag><nodetagid>550</nodetagid>
</nodetag>
</node>
<node><name>#8 In class practice</name>
<id>143</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS3</column>
<textHTML>&lt;p&gt;In-class coding demo for time series provided&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Pipeline for time series data analysis&lt;/li&gt;&lt;li&gt;Important features demo to improve time series model &lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>91.59374237060547</textheight>
<timevalue>60</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>159</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>551</nodetagid>
</nodetag>
<nodetag><nodetagid>554</nodetagid>
</nodetag>
</node>
<node><name>#8 no mapped content</name>
<id>4341</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>undefined</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>100</textheight>
</node>
<node><name>#8 assginment</name>
<id>159</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS2</column>
<textHTML>&lt;ul&gt;&lt;li&gt;continue fine tune models&lt;/li&gt;&lt;li&gt;practice rolling mean&lt;/li&gt;&lt;li&gt;practice cumsum &lt;/li&gt;&lt;li&gt;practice lagged features for time series demo data&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>105.99374389648438</textheight>
<isdropped>true</isdropped>
</node>
</week>
<week><weekid>117</weekid>
<weekname>Week 9: unsupervised learning, K-mean clustering, dimensionality reduction
</weekname>
<node><name>K-means clustering and dimensionality reduction</name>
<id>133</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>AC</column>
<textHTML>&lt;p&gt;Lecture on K-means clustering &amp;amp; Dimensionality Reduction, including the following concepts and topics:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Dimensionality reduction introduction&lt;/li&gt;&lt;li&gt;PCA analysis introduction&lt;/li&gt;&lt;li&gt;Clustering: K-means&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>120.39374542236328</textheight>
<timevalue>90</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>145</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>2479</nodetagid>
</nodetag>
</node>
<node><name>9: Demos: Clustering &amp; PCA</name>
<id>145</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS3</column>
<textHTML>&lt;ul&gt;&lt;li&gt;Demo for clustering&lt;/li&gt;&lt;li&gt;Demo for PCA using images&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>62.79374694824219</textheight>
<timevalue>90</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>147</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<link><targetid>164</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
</node>
<node><name>#9 assignment</name>
<id>164</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS2</column>
<textHTML>&lt;p&gt;&lt;strong&gt;Coding practice. &lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;replay k-means clustering and PCA from demo code&lt;/li&gt;&lt;li&gt;work on project code and push them into production level code base&lt;/li&gt;&lt;li&gt;review ML coding skills and be ready for final test&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>134.7937469482422</textheight>
<isdropped>true</isdropped>
</node>
<node><name>#9 K-means, dimensionality reduction</name>
<id>4342</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;ul&gt;&lt;li&gt;clustering k-means&lt;/li&gt;&lt;li&gt;dimensionality reduction&lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>62.79374694824219</textheight>
<isdropped>true</isdropped>
<nodetag><nodetagid>2479</nodetagid>
</nodetag>
<nodetag><nodetagid>2468</nodetagid>
</nodetag>
</node>
</week>
<week><weekid>116</weekid>
<weekname>Week 10 -Â Final test</weekname>
<node><name>Finalize Project Components</name>
<id>147</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>HW</column>
<textHTML>&lt;p&gt;The final project should contain &lt;/p&gt;&lt;ol&gt;&lt;li&gt;The complete and clean code developed to implement the analyses &lt;/li&gt;&lt;li&gt;A README file briefly summarizing the results obtained and explaining how to reproduce the results&lt;/li&gt;&lt;li&gt;A report of project describing the analysis and findings&lt;/li&gt;&lt;/ol&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>149.19374084472656</textheight>
<isdropped>true</isdropped>
<link><targetid>136</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
</node>
<node><name>Comprehensive in-class final test</name>
<id>136</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>AC</column>
<textHTML>&lt;p&gt;Use selected small data set for final in-class evaluation/test and competition&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>38.79374694824219</textheight>
<timevalue>150</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<link><targetid>4339</targetid>
<portstyle>sourcePort=OUTs;targetPort=INn;</portstyle>
</link>
<nodetag><nodetagid>545</nodetagid>
</nodetag>
<nodetag><nodetagid>557</nodetagid>
</nodetag>
</node>
<node><name>Summary of the course</name>
<id>4339</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS3</column>
<textHTML>&lt;ul&gt;&lt;li&gt;summary the course&lt;/li&gt;&lt;li&gt;further readings/learnings &lt;/li&gt;&lt;/ul&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>62.79374694824219</textheight>
<timevalue>30</timevalue>
<timeunit>min</timeunit>
<isdropped>true</isdropped>
<nodetag><nodetagid>557</nodetagid>
</nodetag>
</node>
</week>
<week><weekid>281</weekid>
<weekname>Not-Needed for the Course</weekname>
<node><name>3: Data Preprocessing 
(Not Needed)</name>
<id>2431</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;p&gt;Introduction to Graphs&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>24</textheight>
</node>
<node><name>6: Introduction to Neural Networks</name>
<id>282</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;p&gt;An Artificial Neuron&lt;/p&gt;&lt;p&gt;Example: 'OR' Neuron Using Sigmoid Activation&lt;/p&gt;&lt;p&gt;Example: Neuron with Rectified Linear Function&lt;/p&gt;&lt;p&gt;One-Layer Neural Network&lt;/p&gt;&lt;p&gt;Example: 'XOR' Neural Network&lt;/p&gt;&lt;p&gt;Deep Training Neural Networks&lt;/p&gt;&lt;p&gt;Lecture Summary: Introduction to Training Neural Networks&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>183</textheight>
</node>
<node><name>7: Training Neural Networks</name>
<id>177</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;p&gt;Stochastic Gradient Descent&lt;/p&gt;&lt;p&gt;The Backpropagation Algorithm&lt;/p&gt;&lt;p&gt;Optimization Difficulties&lt;/p&gt;&lt;p&gt;Optimization Algorithms&lt;/p&gt;&lt;p&gt;Overview of Cross-Validation&lt;/p&gt;&lt;p&gt;Example: Data Preprocessing&lt;/p&gt;&lt;p&gt;Overview of Model Selection&lt;/p&gt;&lt;p&gt;Lecture Summary: Training Neural Networks&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>160</textheight>
</node>
<node><name>8: Convolutional and Recurrent Neural Networks</name>
<id>11</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;p&gt;Object Detection Task&lt;/p&gt;&lt;p&gt;Overview of Convolutional Training Neural Networks&lt;/p&gt;&lt;p&gt;Convolutional Training Neural Networks: Convolutional Layers&lt;/p&gt;&lt;p&gt;Convolutional Training Neural Networks: Pooling Layers&lt;/p&gt;&lt;p&gt;Convolutional Training Neural Networks: A Complete Object Detection Model&lt;/p&gt;&lt;p&gt;Sentiment Classification Task&lt;/p&gt;&lt;p&gt;Recurrent Neural Networks&lt;/p&gt;&lt;p&gt;Deep Recurrent Neural Networks&lt;/p&gt;&lt;p&gt;Lecture Summary: Convolutional and Recurrent Training Neural Networks&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>251</textheight>
</node>
<node><name>9: Data Science for Marketing/Financial Analytics</name>
<id>302</id>
<lefticon>undefined</lefticon>
<righticon>undefined</righticon>
<column>CUS1</column>
<textHTML>&lt;p&gt;Prioritizing Sales Leads&lt;/p&gt;&lt;p&gt;Predicting Credit Card Fraud with Logistic Regression&lt;/p&gt;&lt;p&gt;Estimating Porfolio Risk&lt;/p&gt;&lt;p&gt;Prioritizing Accounts Receivable&lt;/p&gt;&lt;p&gt;RFM Analysis for Customer Segmentation&lt;/p&gt;</textHTML>
<linkedwf>undefined</linkedwf>
<textheight>116</textheight>
</node>
</week>
<wflegendx>940</wflegendx>
<wflegendy>400</wflegendy>
<wfoutcomesorttype>week</wfoutcomesorttype>
</wfdata></workflow>
<tag><tagname>Department Competencies</tagname>
<tagid>541</tagid>
<iscollapsed>true</iscollapsed>
<tag><tagname>Manipulate data structures and implement algorithms</tagname>
<tagid>542</tagid>
<iscollapsed>false</iscollapsed>
<tag><tagname>C - Install libraries and programming tools </tagname>
<tagid>543</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>C - Import data in programing environment</tagname>
<tagid>544</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>C - Design and implement simple algorithms </tagname>
<tagid>549</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>C - Apply existing libraries to data</tagname>
<tagid>550</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>C - Visualize data and models</tagname>
<tagid>551</tagid>
<iscollapsed>true</iscollapsed>
</tag>
</tag>
<tag><tagname>Use best practices for software development</tagname>
<tagid>545</tagid>
<iscollapsed>false</iscollapsed>
<tag><tagname>C - Version code with Git</tagname>
<tagid>546</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>C - Push / pull code from GitHub</tagname>
<tagid>552</tagid>
<iscollapsed>true</iscollapsed>
</tag>
</tag>
<tag><tagname>Data analysis and modelling competencies</tagname>
<tagid>547</tagid>
<iscollapsed>false</iscollapsed>
<tag><tagname>C - Formulate relevant questions about datasets</tagname>
<tagid>553</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>C - Select data modelling techniques to answer a question</tagname>
<tagid>554</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>C - Prepare data for analysis (feature extraction, missing values, train-test-validation sets)</tagname>
<tagid>555</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>C - Apply classification, regression, and clustering to existing data</tagname>
<tagid>556</tagid>
<iscollapsed>true</iscollapsed>
</tag>
</tag>
<tag><tagname>Interpersonal and Leadership competencies </tagname>
<tagid>548</tagid>
<iscollapsed>false</iscollapsed>
<tag><tagname>C - Present critical information to team</tagname>
<tagid>557</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>C - Find resources to solve a technical problem</tagname>
<tagid>558</tagid>
<iscollapsed>true</iscollapsed>
</tag>
</tag>
</tag>
<tag><tagname>Course Objectives</tagname>
<tagid>559</tagid>
<iscollapsed>true</iscollapsed>
<tag><tagname>Understand the broad classes of methods to address machine learning models and data science challenges</tagname>
<tagid>560</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>Understand machine learning workflow/pipeline design and integration as product</tagname>
<tagid>561</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>Understand basic theoretical insights behind ML models/algorithms with some minor math in order to have longer potential for deeper topics in ML</tagname>
<tagid>562</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>Understand how to link the main algorithms to coding and implement thesemethods in machine learning and data analysis, feature engineering and visualization</tagname>
<tagid>563</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>Apply these algorithms on realistic problems using existing software libraries, toolkits or ecosystems in machine learning community</tagname>
<tagid>564</tagid>
<iscollapsed>true</iscollapsed>
</tag>
</tag>
<tag><tagname>ITS Modules</tagname>
<tagid>2454</tagid>
<iscollapsed>true</iscollapsed>
<tag><tagname>Probability Basics</tagname>
<tagid>2455</tagid>
<iscollapsed>false</iscollapsed>
<tag><tagname>K - Normal Distribution</tagname>
<tagid>2456</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Joint and Marginal Probability Distributions</tagname>
<tagid>2457</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Conditional Probability</tagname>
<tagid>2459</tagid>
<iscollapsed>true</iscollapsed>
</tag>
</tag>
<tag><tagname>Data Preprocessing</tagname>
<tagid>2458</tagid>
<iscollapsed>false</iscollapsed>
<tag><tagname>K - What is a Dataset?</tagname>
<tagid>2460</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Exploratory Data Analysis</tagname>
<tagid>2461</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Overview of Data Preprocessing</tagname>
<tagid>2462</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - One-Hot Encoding</tagname>
<tagid>2463</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Feature Importance</tagname>
<tagid>2464</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Feature Selection</tagname>
<tagid>2465</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Feature Scaling</tagname>
<tagid>2466</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Feature Engineering</tagname>
<tagid>2467</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Principal Component Analysis</tagname>
<tagid>2468</tagid>
<iscollapsed>true</iscollapsed>
</tag>
</tag>
<tag><tagname>Machine Learning Models</tagname>
<tagid>2470</tagid>
<iscollapsed>false</iscollapsed>
<tag><tagname>K - Logistic Regression Basic</tagname>
<tagid>2472</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Sigmoid Function</tagname>
<tagid>2473</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Binary Classification</tagname>
<tagid>2474</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Binary Classification for Imbalanced Classes</tagname>
<tagid>2475</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Evaluation Metrics (Classification)</tagname>
<tagid>2476</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Linear Regression</tagname>
<tagid>2477</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Evaluation Metrics (Regression)</tagname>
<tagid>2478</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Clustering</tagname>
<tagid>2479</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Parameters vs. Hyperparameters</tagname>
<tagid>2480</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Hyperparameter Tuning</tagname>
<tagid>2481</tagid>
<iscollapsed>true</iscollapsed>
</tag>
</tag>
<tag><tagname>Machine Learning Overview</tagname>
<tagid>2482</tagid>
<iscollapsed>false</iscollapsed>
<tag><tagname>K - Motivation</tagname>
<tagid>2483</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Supervised Learning</tagname>
<tagid>2484</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Linear Approximators</tagname>
<tagid>2485</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Generalized Linear Approximators</tagname>
<tagid>2486</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Overfitting and Underfitting</tagname>
<tagid>2487</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Overview of Cross-Validation</tagname>
<tagid>2488</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Bias-Variance Decomposition</tagname>
<tagid>2489</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Overview of Logistic Regression</tagname>
<tagid>2490</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Gradient Descent</tagname>
<tagid>2491</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Regularization for Logistic Regression</tagname>
<tagid>2492</tagid>
<iscollapsed>true</iscollapsed>
</tag>
<tag><tagname>K - Lecture Summary: Introduction to Machine Learning</tagname>
<tagid>2493</tagid>
<iscollapsed>true</iscollapsed>
</tag>
</tag>
</tag>
</project>
